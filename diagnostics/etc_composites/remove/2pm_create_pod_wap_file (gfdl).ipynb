{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "for the leoc96, I have to provide the left most values as the lon cordinates, instead of the center point, because if not it causes a crash \n",
    "for the gfdl (2pm) data we have to check this\n",
    "\n",
    "Do I have to do this for all model data? \n",
    "If so, I might have to hard fix the crash that occurs when plotting using basemap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt \n",
    "import cartopy\n",
    "import os\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import netCDF4 as nc\n",
    "\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# reading in LEOC96 data\n",
    "in_folder = '/mnt/drive3/gfdl/6HRLY/SURF/'\n",
    "\n",
    "var = 'wap'\n",
    "var_map = {'wap': 'wap'}\n",
    "var_long_name = {'wap': 'Vertical Velocity'}\n",
    "var_sn = {'wap': 'lagrangian_tendency_of_air_pressure_500'}\n",
    "var_units = {'wap': 'Pa/s'}\n",
    "out_var_map = {'wap': 'wap'}\n",
    "\n",
    "var_scale = {'wap': 1.} \n",
    "\n",
    "in_file = f'/mnt/drive3/gfdl/6HRLY/KLEV/atmos.2008010100-2012123123.{var_map[var]}.nc'\n",
    "print(os.path.exists(in_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 288)\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(in_file)\n",
    "lat_dim = ds.lat.size\n",
    "lon_dim = ds.lon.size\n",
    "dims = ds[var_map[var]].shape[1:]\n",
    "print(dims)\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Variable (time: 7308, pfull: 32, lat: 180, lon: 288)>\n",
      "[12123095040 values with dtype=float32]\n",
      "Attributes:\n",
      "    long_name:      omega\n",
      "    units:          Pa/s\n",
      "    cell_methods:   time: point\n",
      "    interp_method:  conserve_order2\n",
      "<xarray.DataArray 'phalf' (phalf: 33)>\n",
      "array([   1.      ,    4.      ,    8.186021,   13.788865,   20.917952,\n",
      "         29.836408,   41.217896,   55.792215,   74.201906,   97.047864,\n",
      "        124.966648,  158.549553,  198.396959,  245.027221,  298.888576,\n",
      "        360.040179,  427.458025,  498.243573,  568.220535,  633.836047,\n",
      "        693.266329,  745.991986,  792.097373,  831.921945,  865.977814,\n",
      "        894.872525,  919.22792 ,  939.635932,  956.672132,  970.827661,\n",
      "        982.570665,  992.23    , 1000.      ])\n",
      "Coordinates:\n",
      "  * phalf    (phalf) float64 1.0 4.0 8.186 13.79 ... 970.8 982.6 992.2 1e+03\n",
      "Attributes:\n",
      "    long_name:       ref half pressure level\n",
      "    units:           mb\n",
      "    cartesian_axis:  Z\n",
      "    positive:        down\n"
     ]
    }
   ],
   "source": [
    "print(ds.variables[var_map[var]])\n",
    "print(ds.phalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lat = ds['lat'].values\n",
    "in_lon = ds['lon'].values\n",
    "in_var = ds[var_map[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n"
     ]
    }
   ],
   "source": [
    "# year_range = [2008, 2012]\n",
    "year_range = [2008, 2009]\n",
    "\n",
    "time_start_year = 1975\n",
    "\n",
    "# must include the end year, so have to add one \n",
    "num_years = year_range[1] - year_range[0] + 1\n",
    "\n",
    "# creating the output arrays\n",
    "out_time_bnds = np.zeros((1460*num_years, 2))\n",
    "\n",
    "# time variable for all the years\n",
    "in_time = np.arange(0, num_years*365, .25) + (year_range[0] - time_start_year)*365 \n",
    "print(len(in_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2920, 32, 180, 288)\n"
     ]
    }
   ],
   "source": [
    "out_data = in_var.isel(time=range(0,len(in_time)))\n",
    "print(out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_var = np.array(out_data, dtype=np.float32)\n",
    "out_time = in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7300, 2) (180,) (288,) (7300, 180, 288)\n"
     ]
    }
   ],
   "source": [
    "lon = np.copy(in_lon)\n",
    "dlon = lon[1] - lon[0]\n",
    "out_lon = np.round(lon - dlon/2., decimals=2)\n",
    "\n",
    "lat = np.copy(in_lat)\n",
    "dlat = lat[1] - lat[0]\n",
    "out_lat = np.round(lat - dlat/2., decimals=2)\n",
    "\n",
    "# getting the output time bounds\n",
    "out_time_bnds[:, 1] = out_time\n",
    "out_time_bnds[0, 0] = out_time[0]\n",
    "out_time_bnds[1:, 0] = out_time[:-1]\n",
    "\n",
    "print(out_time_bnds.shape, out_lat.shape, out_lon.shape, out_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the date variable provided in model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/anaconda3/envs/mcms/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf533ab4a92043ec828698588d743464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# time_arr = [cftime.DatetimeNoLeap(time_start_year, 1, 1) + dt.timedelta(days=i) for i in tqdm.notebook.tqdm(out_time, total=len(out_time))]\n",
    "out_date = np.empty(out_time.shape, dtype=int)\n",
    "for i, i_time in tqdm.tqdm_notebook(enumerate(out_time), total=len(out_time)): \n",
    "    tmp = cftime.DatetimeNoLeap(time_start_year, 1, 1) + dt.timedelta(days=i_time)\n",
    "    out_date[i] = int('%04d%02d%02d'%(tmp.year, tmp.month, tmp.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20080101 20080101 20080101 ... 20121231 20121231 20121231]\n"
     ]
    }
   ],
   "source": [
    "print(out_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model sample data for the SLP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localdrive/drive10/jj/mdtf/inputdata/model/GFDL.EXP1.2PM.001/6hr/GFDL.EXP1.2PM.001.wap500.6hr.nc\n"
     ]
    }
   ],
   "source": [
    "# write the output as netcdf file \n",
    "\n",
    "# out_file = '/localdrive/drive10/jj/mdtf/inputdata/model/QBOi.EXP1.AMIP.001/6hr/QBOi.EXP1.AMIP.001.SLP.6hr.nc'\n",
    "# out_file = '/localdrive/drive10/jj/mdtf/inputdata/model/GFDL.EXP1.2PM.001/6hr/GFDL.EXP1.2PM.001.SLP.6hr.nc'\n",
    "\n",
    "# out_file = '/localdrive/drive10/jj/mdtf/inputdata/model/GFDL.EXP1.2PM.001/6hr/GFDL.EXP1.2PM.001.SLP.6hr.nc'\n",
    "out_file = f'/localdrive/drive10/jj/mdtf/inputdata/model/GFDL.EXP1.2PM.001/6hr/GFDL.EXP1.2PM.001.{out_var_map[var]}.6hr.nc'\n",
    "print(out_file)\n",
    "\n",
    "# # Format of the PRECT variable for 3hr is as follows: \n",
    "# 1. time - noleap, days since 1975-01-01 00:00:00\n",
    "# 2. date - current date\n",
    "# 3. lat - latitude\n",
    "# 4. lon - longitude\n",
    "# 5. time_bnds - time interval endpoints\n",
    "# 6. SLP - mba, long_name, cell_methods: \"time:mean\"\n",
    "\n",
    "out_ds = xr.Dataset({\n",
    "        'time_bnds': (('time', 'nbnd'), out_time_bnds), \n",
    "        'date': (('time'), out_date),\n",
    "        out_var_map[var]: (('time', 'lat', 'lon'), out_var), \n",
    "    }, \n",
    "    coords={\n",
    "        'time': out_time, \n",
    "        'lat': out_lat, \n",
    "        'lon': out_lon,\n",
    "        'nbnd': [1, 2]\n",
    "    },\n",
    "    )\n",
    "\n",
    "# lon attribs\n",
    "out_ds.lon.attrs['long_name'] = 'longitude'\n",
    "out_ds.lon.attrs['units'] = 'degrees_east'\n",
    "\n",
    "# lat attribs\n",
    "out_ds.lat.attrs['long_name'] = 'latitude'\n",
    "out_ds.lat.attrs['units'] = 'degrees_north'\n",
    "\n",
    "# time attribs\n",
    "out_ds.time.attrs['long_name'] = 'time'\n",
    "out_ds.time.attrs['units'] = 'days since 1975-01-01 00:00:00'\n",
    "out_ds.time.attrs['calendar'] = 'noleap'\n",
    "out_ds.time.attrs['bounds'] = 'time_bnds'\n",
    "\n",
    "# time_bnds attribs\n",
    "out_ds.time_bnds.attrs['long_name'] = 'time interval endpoints'\n",
    "\n",
    "# date attribs\n",
    "out_ds.date.attrs['long_name'] = 'current date (YYYYMMDD)'\n",
    "\n",
    "# slp attribs\n",
    "out_ds[out_var_map[var]].attrs['standard_name'] = var_sn[var]\n",
    "out_ds[out_var_map[var]].attrs['long_name'] = var_long_name[var]\n",
    "out_ds[out_var_map[var]].attrs['units'] = var_units[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually writing the output file\n",
    "out_ds.to_netcdf(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mcms] *",
   "language": "python",
   "name": "conda-env-mcms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
