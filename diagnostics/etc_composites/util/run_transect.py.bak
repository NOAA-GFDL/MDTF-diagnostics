#!/usr/bin/env python

# supressing warnings, because there are a lot of NaN value warnings 
# comment lines below when debugging
# only supress in production
import sys
if not sys.warnoptions:
  import warnings
  warnings.simplefilter("ignore")

import numpy as np 
import front_detection as fd
from scipy.ndimage import label, generate_binary_structure
import glob, os
from netCDF4 import Dataset

import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap
import datetime as dt
import xarray as xr

import cartopy

import defines
import pandas as pd
import reader

## JJ Debugging flags
import pdb, time
from tqdm import tqdm
debug = False
# stop_at_date = dt.datetime(2008, 1, 9)
stop_at_date = None

# ----------------------- FUNCTIONS --------------------------

def extend_lon(var):
  '''
  Extend the logitude on both sides of the longitude by +/- 360 values and pad up and down with nans
  '''

  # extract the size of the input variable
  boxlen = var.shape[1]
  lat_size = var.shape[0]
  lon_size = var.shape[1]

  # extend the variable in both directions by boxlen
  var_new = np.zeros((lat_size, lon_size*3))*np.nan

  var_new[:, 0:lon_size] = var - 360
  var_new[:, lon_size:lon_size*2] = var
  var_new[:, lon_size*2:lon_size*3] = var + 360

  return var_new

def extend_lat(var):
  '''
  Extend the logitude on both sides of the longitude by +/- 360 values and pad up and down with nans
  '''

  # extract the size of the input variable
  boxlen = var.shape[1]
  lat_size = var.shape[0]
  lon_size = var.shape[1]

  # extend the variable in both directions by boxlen
  var_new = np.zeros((lat_size, lon_size*3))*np.nan

  var_new[:, 0:lon_size] = var
  var_new[:, lon_size:lon_size*2] = var
  var_new[:, lon_size*2:lon_size*3] = var

  return var_new

def get_plus_mask(fit, lon, lat):
  lat_prime = lon*fit[0] + fit[1]
  mask = (lat_prime >= lat)
  return mask

def dextend_dist(lat, lon, dist, lon_size, flag=False):

  lat = lat[:, lon_size:lon_size*2]
  lon = lon[:, lon_size:lon_size*2]

  dist_neg = np.copy(dist)
  dist_neg[dist_neg > 0] = np.nan
  dist_3d = np.empty((3, lat.shape[0], lon_size))
  dist_3d[0, :, :] = dist_neg[:, 0:lon_size]
  dist_3d[1, :, :] = dist_neg[:, lon_size:lon_size*2]
  dist_3d[2, :, :] = dist_neg[:, lon_size*2:]
  # dist_neg = np.nanmax(dist_3d, axis=0)
  if (flag):
    dist_neg = np.nanmin(dist_3d, axis=0)
  else:
    dist_neg = dist_3d[1, :, :]
  
  dist_pos = np.copy(dist)
  dist_pos[dist_pos < 0] = np.nan
  dist_3d = np.empty((3, lat.shape[0], lon_size))
  dist_3d[0, :, :] = dist_pos[:, 0:lon_size]
  dist_3d[1, :, :] = dist_pos[:, lon_size:lon_size*2]
  dist_3d[2, :, :] = dist_pos[:, lon_size*2:]

  if (flag):
    dist_pos = np.nanmin(dist_3d, axis=0)
  else:
    dist_pos = dist_3d[1, :, :]

  dist = np.copy(dist_pos)
  dist[np.isnan(dist_pos)] = dist_neg[np.isnan(dist_pos)]

  # # for the southern hemisphere, I have to copy the negative values to overwrite the positive values
  # # why do I have to do this? 
  # SH = (lat < 0)
  # dist[~np.isnan(dist_neg ) & SH] = dist_neg[~np.isnan(dist_neg ) & SH]

  return lat, lon, dist

def get_dist_from_front(fit, lon, lat, indexes, f_type='cf', debug_append=''):

  # extend lat and lon on both sides
  lon_size = lat.shape[1]
  lon = extend_lon(lon)
  lat = extend_lat(lat)

  # get the distance from the straight line

  front_slope = fit[0]
  front_intercept = fit[1]

  # getting the slope of the perpendicular line
  perp_slope = -1/front_slope

  # getting the intercept using the cdt lon and lat values
  perp_intercept = lat - perp_slope*lon

  # point of intercept of perpendicular & front line 
  tmp_lon = (front_intercept - perp_intercept)/(perp_slope - front_slope)
  tmp_lat = perp_slope * tmp_lon + perp_intercept

  # getting distance
  # dist = np.sqrt((lat - tmp_lat)**2 + (lon - tmp_lon)**2)*np.cos(lat*np.pi/180.)*111.12
  # dist = fd.dist_between_grids(lat, lon, tmp_lat, tmp_lon)
  # dist = fd.compute_dist_from_cdt(lat, lon, tmp_lat, tmp_lon)
  dist = fd.dist_transect(lat, lon, tmp_lat, tmp_lon)

  left_edge_lat = np.abs(front_slope * (0) + front_intercept)
  right_edge_lat = np.abs(front_slope * (360) + front_intercept)
  if (left_edge_lat > 90) | (right_edge_lat > 90): 
    dextend_flag = True
  else:
    dextend_flag = False

  # screening out any values greater than 1500
  dist_orig = np.copy(dist) # testing JJ
  dist[dist > 1500] = np.nan

  # check if cf or wf, and make -/+ depending on that
  if (f_type == 'cf'):
    neg_mask = (lon < tmp_lon)
  elif (f_type == 'wf'):
    neg_mask = (np.abs(lat) < np.abs(tmp_lat))

  # making the distances +/- depending on mask
  dist[neg_mask] *= -1

  dist[np.abs(lat) > 75] = np.nan

  # if (debug):
  #   plt.close('all')
  #   ax = plt.axes(projection=cartopy.crs.PlateCarree())
  #   ax.coastlines(lw=1., alpha=.5)
  #   plt.pcolormesh(lon, lat, dist, cmap='bwr', vmin=-500, vmax=500)
  #   plt.colorbar()
  #   plt.plot(lon[0, :], np.poly1d(fit)(lon[0, :]), 'r', lw=2., label='Front')
  #   plt.savefig(f'./images/cases/{debug_append}_dist_{f_type}.png', dpi=300)

  # loop through all my cold front points, 
  # and get the min and max values, i.e. places I need to chop off my front line
  if (f_type == 'cf'):
    mask_greater = np.ones(lat.shape)
    mask_less = np.ones(lon.shape)
    for idx in indexes: 
      ps = perp_slope
      pi = perp_intercept[idx[0], idx[1]+lon_size]
      
      i_tmp_lat = lon*ps + pi
      mask_greater[i_tmp_lat < lat] = 0.
      mask_less[i_tmp_lat > lat] = 0.
    
    dist[mask_less == 1] = np.nan
    dist[mask_greater == 1] = np.nan
  elif (f_type == 'wf'):
    mask_greater = np.ones(lat.shape)
    mask_less = np.ones(lon.shape)
    for idx in indexes: 
      ps = perp_slope
      pi = perp_intercept[idx[0], idx[1]+lon_size]
      
      # i_tmp_lat = lon*ps + pi
      # mask_greater[i_tmp_lat < lat] = 0.
      # mask_less[i_tmp_lat > lat] = 0.
      
      i_tmp_lon = (lat-pi)/ps
      mask_greater[i_tmp_lon < lon] = 0.
      mask_less[i_tmp_lon > lon] = 0.
      
    dist[mask_less == 1] = np.nan
    dist[mask_greater == 1] = np.nan
 
  # if (debug):
  #   plt.close('all')
  #   ax = plt.axes(projection=cartopy.crs.PlateCarree())
  #   ax.coastlines(lw=1., alpha=.5)
  #   plt.pcolormesh(lon, lat, dist, cmap='bwr', vmin=-500, vmax=500)
  #   plt.colorbar()
  #   plt.plot(lon[0, :], np.poly1d(fit)(lon[0, :]), 'r', lw=2., label='Front')
  #   plt.savefig(f'./images/cases/{debug_append}_cropped_dist_{f_type}.png', dpi=300)

  # dextending the distance 3d 
  lat, lon, dist = dextend_dist(lat, lon, dist, lon_size, flag=dextend_flag)
  
  return dist

# ----------------------- MAIN CODE ---------------------------
start_time = time.time()
# Main Code 
# plt.style.use(['ggplot', 'classic'])
plt.style.use(['seaborn-talk', 'ggplot'])

year_list = range(defines.transect_years[0], defines.transect_years[1]+1)
# Debug: overwriting the year list

# getting land ocean mask for era-interim
# ds = xr.open_dataset('/localdrive/drive6/erai/invariants.nc')
ds = xr.open_dataset(defines.topo_file)
if ('time' in ds.coords.keys()):
  lm = ds.lsm.isel(time=0).values
else:
  lm = ds.lsm.values
lm = (lm > defines.thresh_landsea/100.)
ds.close()

# creating the transect analysis
front_dist_bins = np.arange(-1450, 1550, 100)
height_bins = np.arange(0, 15, 1)

front_dist_bins_mid = front_dist_bins[:-1] + (front_dist_bins[1] - front_dist_bins[0])/2.
height_bins_mid = height_bins[:-1] + (height_bins[1] - height_bins[0])/2.

transect = {}
transect['front_dist'] = front_dist_bins_mid
transect['height'] = height_bins_mid
hemis = ['NH', 'SH']
front_types = ['cf', 'wf']
for var_name in defines.transect_var_list: 
  transect[var_name] = {}
  for i_hemis in hemis: 
    transect[var_name][i_hemis] = {}
    for i_type in front_types: 
      transect[var_name][i_hemis][i_type] = {}
      for i_lm in ['land', 'ocean']:
        transect[var_name][i_hemis][i_type][i_lm] = {}
        for i_season in ['all', 'djf', 'jja', 'mam', 'son', 'warm']:
          transect[var_name][i_hemis][i_type][i_lm][i_season] = {'sum': np.zeros((len(front_dist_bins_mid), len(height_bins_mid))), 'cnts': np.zeros((len(front_dist_bins_mid), len(height_bins_mid)))}

for year in year_list: 
  print('Debug: Reading in data ...', end=" ")

  # filenames for the necessary files
  slp_file = os.path.join(defines.slp_data_directory, f'slp.{year}.nc')
  front_file = os.path.join(defines.fronts_folder, f'fronts_{defines.model}_{year}.nc')

  # getting hte info for the model and fronts data
  model_slp = xr.open_dataset(slp_file)
  fronts = xr.open_dataset(front_file)

  # make sure that the fronts lon/lat are the same as the variable lat/lon
  assert(np.all((model_slp.lon - fronts.lon) == 0) & np.all((model_slp.lat - fronts.lat) == 0.))

  # creating the cdt grid 
  lon, lat = np.meshgrid(model_slp.lon, model_slp.lat)

  print(' Completed!')
    
  ############# Get Centers for the given date ######################
  in_file = os.path.join(defines.read_folder, f'{defines.model}_{year}.mat')
  all_centers = reader.read_center_from_mat_file(in_file)

  # loop through all hte time steps in the year
  for t_step in tqdm(range(1, len(fronts.time)), total=len(fronts.time), desc=f'{year}: '):

    # creating a datetime variable for the current time step
    date = pd.Timestamp(fronts.time[t_step].values).to_pydatetime()
    model_slp_tstep = model_slp.isel(time=t_step)
    fronts_tstep = fronts.isel(time=t_step)

    # getting the season for the given time step date
    t_step_month = date.month
    if (t_step_month == 12) | (t_step_month == 1) | (t_step_month == 2):
      t_season = 'djf'
    elif (t_step_month == 3) | (t_step_month == 4) | (t_step_month == 5):
      t_season = 'mam'
    elif (t_step_month == 6) | (t_step_month == 7) | (t_step_month == 8):
      t_season = 'jja'
    elif (t_step_month == 9) | (t_step_month == 10) | (t_step_month == 11):
      t_season = 'son'

    t_season_warm = False
    if (t_step_month == 11) | (t_step_month == 12) | (t_step_month == 1) | (t_step_month == 2) | (t_step_month == 3):
      t_season_warm = True

    # check if the t_season is requested in the defines.py
    # atleast 'all' should be given in the season_list
    if ('all' not in defines.transect_season_list) & (t_season not in defines.transect_season_list) & ('warm' not in defines.transect_season_list): 
      continue
    
    # minutes = np.asscalar(fronts.time[t_step].values)
    # date = dt.datetime(year, 1, 1) + dt.timedelta(minutes=minutes)
  
    fd_date = date
    centers = all_centers.find_centers_for_date(fd_date)

    for i_center, _  in enumerate(centers.lat): 
      date_str = fd_date.strftime('%Y%m%d%H')
      debug_append = f'{date_str}{i_center:03d}'
      center = {}
      for key in centers.keys():
        center[key] = centers[key][i_center]

      # # debug: running only for edge cases
      # if not ((center['lon'] < -165) | (center['lon'] > 165)):
      #   continue

      # distance from given center
      dist_grid = fd.compute_dist_from_cdt(lat, lon, center['lat'], center['lon'])
      mask_valid_fronts = (dist_grid < 1500)
      
      # index of center of cyclone
      c_ind = np.nanargmin(dist_grid)
      cx, cy = np.unravel_index(c_ind, dist_grid.shape)
      lm_flag = lm[cx, cy]
      if (lm_flag): 
        lm_type = 'land'
      else:
        lm_type = 'ocean'

      # # ------------- Uncomment this if all_centers.find_centers_for_date() gives different results as when creating the front_detection
      #
      # # getting all the fronts for the given date
      # cf_mask = fronts_tstep.cf.values >= 1
      # wf_mask = fronts_tstep.wf.values >= 1
      #
      # # find the fronts that are associated with the given center
      # # storm attribution; 
      # # check for the fronts within 500m
      # # pick the cases with most values within the mask
      # cf_uni, cf_uni_cnts = np.unique(fronts_tstep.cf.values[cf_mask & mask_valid_fronts], return_counts=True)
      # wf_uni, wf_uni_cnts = np.unique(fronts_tstep.wf.values[wf_mask & mask_valid_fronts], return_counts=True)
      #
      # if (len(cf_uni) == 0) & (len(wf_uni) == 0): 
      #   continue
      #
      # cf_flag = False
      # if (len(cf_uni) == 1): 
      #   cf_mask = (fronts_tstep.cf.values == cf_uni[0])
      #   cf_flag = True
      # elif(len(cf_uni) >= 1):
      #   cf_uni_max = np.nanargmax(cf_uni)
      #   cf_mask = (fronts_tstep.cf.values == cf_uni[cf_uni_max])
      #   cf_flag = True
      # else: 
      #   # don't do anything
      #   cf_flag = False
      #
      # wf_flag = False
      # if (len(wf_uni) == 1): 
      #   wf_mask = (fronts_tstep.wf.values == wf_uni[0])
      #   wf_flag = True
      # elif(len(wf_uni) > 1):
      #   wf_uni_max = np.nanargmax(wf_uni)
      #   wf_mask = (fronts_tstep.wf.values == wf_uni[wf_uni_max])
      #   wf_flag = True
      # else: 
      #   # don't do anything
      #   wf_flag = False

      # simpler solution to the above
      # if we use this code, then make sure it works as intended.
      # technically it should
      cf_mask = (fronts_tstep.cf.values == i_center + 1)
      cf_flag = False
      if (np.any(cf_mask)):
        cf_flag = True

      wf_mask = (fronts_tstep.wf.values == i_center + 1)
      wf_flag = False
      if (np.any(wf_mask)):
        wf_flag = True

      # if no warm or cold front, then just skip this center
      if (not wf_flag) & (not cf_flag): 
        continue

      # filtering out cyclones with centers within 30-60 N/S
      if (np.abs(center['lat']) > 60) | (np.abs(center['lat']) < 30):
        continue
      
      if (cf_flag):
        # getting the lat, lon of the fronts for the diven date
        cf_indexes = np.argwhere(cf_mask)
        cf_lat = lat[cf_mask]
        cf_lon = lon[cf_mask]
        cf_weights = dist_grid[cf_mask]

        # # adding center point before fitting the front line
        # cf_lon = np.append(cf_lon, center['lon'])
        # cf_lat = np.append(cf_lat, center['lat'])
        # cf_weights = np.append(cf_weights, np.nanmax(cf_weights))

        # # fitting a line through the front points
        # # weight it according to how far away from the center the values are
        # cf_fit = np.polyfit(cf_lon, cf_lat, 1, w=1/cf_weights)
      
        # fitting a line through the front points
        # non weighted fit
        cf_fit = np.polyfit(cf_lon, cf_lat, 1)
        
        # getting distance from the front line fit
        dist_from_front_cf = get_dist_from_front(cf_fit, lon, lat, cf_indexes, 'cf', debug_append)
        dist_from_front_cf[(dist_grid > 5000) | (dist_grid < 500)] = np.nan
        # dist_from_front_cf[(dist_grid > 5000)] = np.nan
       
        # if (debug):
        #   # Debug: plotting
        #   plt.close('all')
        #   ax = plt.axes(projection=cartopy.crs.PlateCarree())
        #   ax.coastlines(lw=1., alpha=.5)
        #   plt.pcolormesh(lon, lat, dist_from_front_cf, cmap='bwr', vmin=-500, vmax=500)
        #   plt.colorbar()
        #   plt.plot(lon[0, :], np.poly1d(cf_fit)(lon[0, :]), 'r', lw=2., label='Front')
        #   plt.plot(lon[cx,cy], lat[cx,cy], 'g*', markersize=10, label='Point')
        #   plt.savefig(f'./images/cases/{debug_append}_cropped_dist_cf.png', dpi=300)

      if (wf_flag):
        wf_indexes = np.argwhere(wf_mask)
        wf_lat = lat[wf_mask]
        wf_lon = lon[wf_mask]
        wf_weights = dist_grid[wf_mask]


        wf_lon = np.append(wf_lon, center['lon'])
        wf_lat = np.append(wf_lat, center['lat'])
        wf_weights = np.append(wf_weights, np.nanmax(wf_weights))

        # # fitting a line through the front points
        # # weight it according to how far away from the center the values are
        # wf_fit = np.polyfit(wf_lon, wf_lat, 1, w=1/wf_weights)
        
        # fitting a line through the front points
        # non weighted fit
        wf_fit = np.polyfit(wf_lon, wf_lat, 1)
        
        # getting the distance from the front line
        dist_from_front_wf = get_dist_from_front(wf_fit, lon, lat, wf_indexes, 'wf', debug_append)
        dist_from_front_wf[(dist_grid > 5000) | (dist_grid < 500)] = np.nan
        # dist_from_front_wf[(dist_grid > 5000)] = np.nan

        # if (debug):
        #   # Debug: plotting
        #   plt.close('all')
        #   ax = plt.axes(projection=cartopy.crs.PlateCarree())
        #   ax.coastlines(lw=1., alpha=.5)
        #   plt.pcolormesh(lon, lat, dist_from_front_wf, cmap='bwr', vmin=-500, vmax=500)
        #   plt.colorbar()
        #   plt.plot(lon[0, :], np.poly1d(wf_fit)(lon[0, :]), 'r', lw=2., label='Front')
        #   plt.plot(lon[cx,cy], lat[cx,cy], 'g*', markersize=10, label='Point')
        #   plt.savefig(f'./images/cases/{debug_append}_cropped_dist_wf.png', dpi=300)
       
      # if (debug):
      #   # Debug: plotting fronts
      #   plt.close('all')
      #   plt.figure()
      #   ax = plt.axes(projection=cartopy.crs.PlateCarree())
      #   ax.coastlines()
      #   ax.set_global()
      #   if (cf_flag):
      #     ax.plot(cf_lon, cf_lat, 'b*')
      #   if (wf_flag):
      #     ax.plot(wf_lon, wf_lat, 'r*')
      #   ax.plot(center['lon'], center['lat'], 'y*')
      #   plt.savefig(f'./images/cases/{debug_append}_tmp.png', dpi=300.)

      # Geo-potential height (3d) file datasets
      model_z = xr.open_dataset(os.path.join(defines.var_data_directory, f'z.{year}.nc'))
      model_z_tstep = model_z.isel(time=t_step)

      # repeat distance matrix into 3d structure 
      if (cf_flag):
        # ------------------------------------ CF 
        # create the distance from front as 3d matrix
        dist_3d = np.repeat(dist_from_front_cf[np.newaxis, :, :], len(model_z_tstep.lev), axis=0)
        front_type = 'cf'

        # loop through all the 3d variables, and create the transects
        for var_ind, var_name in enumerate(defines.transect_var_list):
          
          # variable dataset
          model_var = xr.open_dataset(os.path.join(defines.var_data_directory, f'{var_name}.{year}.nc'))

          # getting the time step
          model_var_tstep = model_var.isel(time=t_step)

          # masking out the Z values for region that we need to compute transects for
          model_z_tstep.coords['mask'] = (('lat', 'lon'), ~np.isnan(dist_from_front_cf))
          model_var_tstep.coords['mask'] = (('lat', 'lon'), ~np.isnan(dist_from_front_cf))

          # z_values
          model_z_mask = model_z_tstep.where(model_z_tstep.mask == 1)
          model_dist = dist_3d.flatten()
          model_H = (model_z_mask.z).values.flatten()

          # var values
          model_var_mask = model_var_tstep.where(model_var_tstep.mask == 1)
          model_val = (model_var_mask[var_name]).values.flatten()

          ind = ~np.isnan(model_dist) & ~np.isnan(model_H) & ~np.isnan(model_val)

          # Using only model values above a given threshold
          if (defines.transect_var_thres[var_ind] is not None): 
            ind = ind & (model_val > defines.transect_var_thres[var_ind])

          H_sum, x,y = np.histogram2d(model_dist[ind], model_H[ind], bins=(front_dist_bins, height_bins), weights=model_val[ind])
          H_cnts, x,y = np.histogram2d(model_dist[ind], model_H[ind], bins=(front_dist_bins, height_bins))

          H = H_sum/H_cnts

          if (center['lat'] < 0):
            hemis = 'SH'
          elif (center['lat'] >= 0):
            hemis = 'NH'
          transect[var_name][hemis][front_type][lm_type]['all']['sum'] += H_sum
          transect[var_name][hemis][front_type][lm_type]['all']['cnts'] += H_cnts
         
          if (t_season_warm):
            transect[var_name][hemis][front_type][lm_type]['warm']['sum'] += H_sum
            transect[var_name][hemis][front_type][lm_type]['warm']['cnts'] += H_cnts
          
          # incrementing the sum and cnt of the appropriate season
          transect[var_name][hemis][front_type][lm_type][t_season]['sum'] += H_sum
          transect[var_name][hemis][front_type][lm_type][t_season]['cnts'] += H_cnts

          # close the 3d var file
          model_var.close()
         
          if (debug): 
            plt.close('all')
            plt.contourf(transect['front_dist'], transect['height'],H.T);
            plt.colorbar(); 
            plt.title(f'Across {front_type.upper()}: {var_name}')
            plt.savefig(os.path.join(defines.images_folder,f'debug_{debug_append}_transect_{var_name}_{front_type}.png'), dpi=300.)
    
      if (wf_flag):
        # ------------------------------------ WF 
        # create the distance from front as 3d matrix
        dist_3d = np.repeat(dist_from_front_wf[np.newaxis, :, :], len(model_z_tstep.lev), axis=0)
        front_type = 'wf'

        # loop through all the 3d variables, and create the transects
        for var_ind, var_name in enumerate(defines.transect_var_list):
          
          # variable dataset
          model_var = xr.open_dataset(os.path.join(defines.var_data_directory, f'{var_name}.{year}.nc'))

          # getting the time step
          model_var_tstep = model_var.isel(time=t_step)

          # masking out the Z values for region that we need to compute transects for
          model_z_tstep.coords['mask'] = (('lat', 'lon'), ~np.isnan(dist_from_front_wf))
          model_var_tstep.coords['mask'] = (('lat', 'lon'), ~np.isnan(dist_from_front_wf))

          # z_values
          model_z_mask = model_z_tstep.where(model_z_tstep.mask == 1)
          model_dist = dist_3d.flatten()
          model_H = (model_z_mask.z).values.flatten()

          # var values
          model_var_mask = model_var_tstep.where(model_var_tstep.mask == 1)
          model_val = (model_var_mask[var_name]).values.flatten()

          ind = ~np.isnan(model_dist) & ~np.isnan(model_H) & ~np.isnan(model_val)
          
          # Using only model values above a given threshold
          if (defines.transect_var_thres[var_ind] is not None): 
            ind = ind & (model_val > defines.transect_var_thres[var_ind])

          H_sum, x,y = np.histogram2d(model_dist[ind], model_H[ind], bins=(np.arange(-1450, 1550, 100), np.arange(0, 15, 1.)), weights=model_val[ind])
          H_cnts, x,y = np.histogram2d(model_dist[ind], model_H[ind], bins=(np.arange(-1450, 1550, 100), np.arange(0, 15, 1.)))
          x_mid = x[:-1] + (x[1] - x[0])/2.
          y_mid = y[:-1] + (y[1] - y[0])/2.

          H = H_sum/H_cnts
          
          if (center['lat'] < 0):
            hemis = 'SH'
          elif (center['lat'] >= 0):
            hemis = 'NH'
          transect[var_name][hemis][front_type][lm_type]['all']['sum'] += H_sum
          transect[var_name][hemis][front_type][lm_type]['all']['cnts'] += H_cnts

          if (t_season_warm):
            transect[var_name][hemis][front_type][lm_type]['warm']['sum'] += H_sum
            transect[var_name][hemis][front_type][lm_type]['warm']['cnts'] += H_cnts
         
          # incrementing the sum and cnt of the appropriate season
          transect[var_name][hemis][front_type][lm_type][t_season]['sum'] += H_sum
          transect[var_name][hemis][front_type][lm_type][t_season]['cnts'] += H_cnts

          # close the 3d var file
          model_var.close()
         
          if (debug):
            plt.close('all')
            plt.contourf(transect['front_dist'], transect['height'], H.T);
            plt.colorbar(); 
            plt.title(f'Across {front_type.upper()}: {var_name}')
            plt.savefig(os.path.join(defines.images_folder,f'debug_{debug_append}_transect_{var_name}_{front_type}.png'), dpi=300.)
     
      # close the 3d z file
      model_z.close()

      if (debug):
        plt.close('all')
        ax1 = plt.subplot(1,2,1, projection=cartopy.crs.PlateCarree())
        ax2 = plt.subplot(1,2,2, projection=cartopy.crs.PlateCarree())
        if (cf_flag):
          # plotting the Cloud front and the mask 
          ax1.coastlines(lw=.5, alpha=0.5)
          div = 50 
          ax1.set_extent([center['lon']-div, center['lon']+div, center['lat']-div, 90])
          # ax.set_global()
          pc = ax1.pcolormesh(lon, lat, np.double(dist_from_front_cf), cmap='bwr', vmin=-1500, vmax=1500)
          ax1.plot(model_slp.lon, np.poly1d(cf_fit)(model_slp.lon), 'k--', lw=2.)
          ax1.plot(center['lon'], center['lat'], 'y*', markersize=15)
          ax1.plot(cf_lon, cf_lat, 'b*', markersize=5)
          plt.colorbar(pc, ax=ax1)
          ax1.set_title('Cold Front')
       
        if (wf_flag):
          ax2.coastlines(lw=.5, alpha=0.5)
          div = 50 
          ax2.set_extent([center['lon']-div, center['lon']+div, center['lat']-div, 90])
          # ax.set_global()
          pc = ax2.pcolormesh(lon, lat, np.double(dist_from_front_wf), cmap='bwr', vmin=-1500, vmax=1500)
          ax2.plot(model_slp.lon, np.poly1d(wf_fit)(model_slp.lon), 'k--', lw=2.)
          ax2.plot(center['lon'], center['lat'], 'y*', markersize=15)
          ax2.plot(wf_lon, wf_lat, 'r*', markersize=5)
          plt.colorbar(pc, ax=ax2)
          ax2.set_title('Warm Front')

        plt.tight_layout()
        plt.savefig(os.path.join(defines.images_folder, f'debug_{debug_append}_fronts_dist_{var_name}_{front_type}.png'), dpi=300.)

    # if (date > dt.datetime(1979, 1, 10)): 
    if (stop_at_date is not None): 
      if (date > stop_at_date): 
        print('Done!')
        break

  if (stop_at_date is not None):
    break

print(f'--- {time.time() - start_time} seconds --- ')

# ---------------- Plotting the transect analysis outputs -------------------
# Creating plots for the various variables 

import pickle
pickle.dump(transect, open(os.path.join(defines.read_folder, 'tmp.pkl'), 'wb'))

for season in defines.transect_season_list:
  # Looping through all the 3d variables 
  for var_name in defines.transect_var_list:
    # Looping through the different hemispheres
    for hemis in defines.transect_hemis_list:
      plt.close('all')
      plt.figure()

      if (var_name == 'T'):
        levels = np.arange(210, 290, 10);  cmap='default' # T
      elif (var_name in ['U', 'V']):
        levels = np.arange(-40, 40, 5); cmap='bwr' # U
      else: 
        levels = 20; cmap='viridis'
      plt.subplot(2,2,1)
      ftype = 'cf'
      lm_type = 'ocean'
      tmp = (transect[var_name][hemis][ftype][lm_type][season]['sum']/transect[var_name][hemis][ftype][lm_type][season]['cnts']).T
      # plt.contourf(transect['front_dist'], transect['height'], tmp, levels=levels, extend='both', cmap=cmap);
      plt.pcolormesh(transect['front_dist'], transect['height'], tmp, cmap=cmap);
      plt.colorbar(); 
      plt.title(f'Across {hemis.upper()} - {lm_type.upper()}, {ftype.upper()}: {var_name.upper()} {season.upper()}')

      plt.subplot(2,2,2)
      ftype = 'wf'
      lm_type = 'ocean'
      tmp = (transect[var_name][hemis][ftype][lm_type][season]['sum']/transect[var_name][hemis][ftype][lm_type][season]['cnts']).T
      # plt.contourf(transect['front_dist'], transect['height'], tmp, levels=levels, extend='both', cmap=cmap);
      plt.pcolormesh(transect['front_dist'], transect['height'], tmp, cmap=cmap);
      plt.colorbar(); 
      plt.title(f'Across {hemis.upper()} - {lm_type.upper()}, {ftype.upper()}: {var_name.upper()} {season.upper()}')

      plt.subplot(2,2,3)
      ftype = 'cf'
      lm_type = 'land'
      tmp = (transect[var_name][hemis][ftype][lm_type][season]['sum']/transect[var_name][hemis][ftype][lm_type][season]['cnts']).T
      # plt.contourf(transect['front_dist'], transect['height'], tmp, levels=levels, extend='both', cmap=cmap);
      plt.pcolormesh(transect['front_dist'], transect['height'], tmp, cmap=cmap);
      plt.colorbar(); 
      plt.title(f'Across {hemis.upper()} - {lm_type.upper()}, {ftype.upper()}: {var_name.upper()} {season.upper()}')

      plt.subplot(2,2,4)
      ftype = 'wf'
      lm_type = 'land'
      tmp = (transect[var_name][hemis][ftype][lm_type][season]['sum']/transect[var_name][hemis][ftype][lm_type][season]['cnts']).T
      # plt.contourf(transect['front_dist'], transect['height'], tmp, levels=levels, extend='both', cmap=cmap);
      plt.pcolormesh(transect['front_dist'], transect['height'], tmp, cmap=cmap);
      plt.colorbar(); 
      plt.title(f'Across {hemis.upper()} - {lm_type.upper()}, {ftype.upper()}: {var_name.upper()} {season.upper()}')

      plt.tight_layout()
      out_file = os.path.join(defines.images_folder, f'{defines.model}_{defines.transect_years[0]}_{defines.transect_years[1]}_transect_{hemis.upper()}_{var_name.upper()}_{season.upper()}.png')
      plt.savefig(out_file, dpi=300.) 
